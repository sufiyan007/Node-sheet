# ğŸŸ¦ Phase 1 â€” Node.js Core Concepts

## 1ï¸âƒ£ What is Node.js?
Node.js is a **JavaScript runtime environment** built on the **V8 engine**, used to run JavaScript on the server (outside the browser).  
It provides non-blocking I/O, single-threaded JS + multi-threaded internals, and is ideal for fast, scalable backend systems.

---

## 2ï¸âƒ£ How Node Works (V8 + Libuv)
Node.js works using two main components:

### âœ”ï¸ V8 Engine  
- Executes JavaScript  
- Converts JS â†’ Machine code  
- Extremely fast  

### âœ”ï¸ libuv  
- Provides **event loop**  
- Handles **async I/O**  
- Has a **thread pool**  
- Manages timers, file system, DNS, network operations  

Together:  
JS runs on V8 â†’ async tasks go to libuv â†’ event loop picks callbacks â†’ results return to JS.

---

## 3ï¸âƒ£ Event Loop

When Node.js runs your file, the JavaScript code is first given to the V8 engine, which parses it, compiles it, and converts it into machine code. Once compiled, Node starts executing all synchronous JavaScript on the call stack. The call stack is simply the place where immediate code runs â€” for example, a console.log("Hi") goes straight to the stack, runs instantly, and is removed. Only one thing runs at a time, because JavaScript is single-threaded.

Whenever your code contains an asynchronous operation such as setTimeout, Promise.then, or fs.readFile, JavaScript doesnâ€™t execute those. Instead, it registers the callback and hands the work to libuv (a C library used internally by Node). Libuv performs the async task in the background while JavaScript continues executing synchronous lines without waiting. This is how Node stays non-blocking.

After the synchronous part of your code finishes for the current turn, Node begins processing anything waiting in the async queues. Node has three important queues, and each one has a different execution priority:

**process.nextTick()** has the highest priority. Anything scheduled using nextTick runs immediately after the current synchronous code completes. This queue runs before every other queue.

**Microtask Queue** is where Promise.then and queueMicrotask callbacks go. Microtasks run right after nextTick, and they run to completion before Node moves on.

**Macrotask Queue** (also called the callback queue) contains things like setTimeout, setInterval, setImmediate, file system events, and network responses. These run only after nextTick and microtasks finish.

Everything â€” nextTick, microtasks, macrotasks â€” eventually gets executed on the call stack, because the call stack is the only place JavaScript can actually run code.

To understand this flow, consider your example:

```js
console.log("1");

process.nextTick(() => console.log("nextTick"));

Promise.resolve().then(() => console.log("promise"));

setTimeout(() => console.log("timeout"), 0);

console.log("2");
```

The two console.log statements (1 and 2) run immediately on the call stack because they are synchronous.
After synchronous execution finishes, Node checks the async queues.

First, the nextTick callback runs because it has the highest priority. So "nextTick" goes to the call stack and gets executed immediately.

Next, Node processes the microtask queue, so the promise callback ("promise") is taken and executed on the call stack.

Finally, after microtasks are done, Node moves to the macrotask queue, where the setTimeout callback is waiting. "timeout" is then executed.

### Final Output:
```
1
2
nextTick
promise
timeout
```

### Code Table

| Code | What Happens |
|------|--------------|
| console.log("1") | Goes to Call Stack â†’ print â†’ removed |
| process.nextTick(..) | Callback goes to Next Tick Queue |
| Promise.then(..) | Callback goes to Microtask Queue |
| setTimeout(..) | Timer â†’ after 0ms â†’ callback goes to Macrotask Queue |
| console.log("2") | Goes to Call Stack â†’ print â†’ removed |

Now sync code is done.

---
## 4ï¸âƒ£ Libuv & Thread Pool


## ğŸ”µ CPU vs IO Tasks (Super Simple)

### **IO Tasks**
Examples:
- Reading/writing files  
- Network requests  
- Database queries  
- Timers  

âœ”ï¸ Fast for CPU, slow because they wait on external systems  
âœ”ï¸ Handled by **libuv + OS**, not JavaScript  
âœ”ï¸ **Do NOT block** the main thread  
âœ”ï¸ Node continues running other code smoothly  

---

### **CPU Tasks**
Examples:
- bcrypt hashing  
- crypto operations  
- gzip compression  
- image processing  
- heavy JSON parsing  

â— Heavy computation work  
â— Executed inside **libuv's thread pool**  
â— Too many CPU tasks â†’ thread pool busy â†’ slower API responses  

---

## ğŸ”µ Blocking vs Non-Blocking

### **Non-Blocking (Recommended)**
```js
fs.readFile("file.txt", () => {});
```
âœ”ï¸ Work done by libuv  
âœ”ï¸ Event loop free  
âœ”ï¸ Node handles thousands of requests  
âœ”ï¸ Callback runs later  

---

### **Blocking (Avoid in backend)**
```js
fs.readFileSync("file.txt");
```
âŒ Main thread freezes until file completes  
âŒ Stops entire event loop  
âŒ Only one request runs at a time  
âŒ Causes slowdowns under load  

---

## ğŸ”µ UV_THREADPOOL_SIZE (Why This Matters)

- Nodeâ€™s libuv thread pool has **4 threads by default**
- These threads handle CPU-heavy async tasks like:
  - bcrypt hashing  
  - crypto.pbkdf2  
  - gzip compression  
  - some fs operations  
  - DNS lookups  

---

### **Increase thread pool size if your app does heavy CPU work**
```js
process.env.UV_THREADPOOL_SIZE = 32;
```

Useful when:
- Many users logging in at once (bcrypt heavy)
- File processing service
- Compression/encryption pipelines
- High concurrency with CPU-based tasks

---
